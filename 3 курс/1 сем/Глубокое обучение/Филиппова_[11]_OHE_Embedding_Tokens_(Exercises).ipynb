{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0429492f",
      "metadata": {
        "id": "0429492f"
      },
      "source": [
        "# Виды признаков\n",
        "\n",
        "В машинном обучении данные обычно делятся на несколько типов:\n",
        "\n",
        "- Категориальные признаки: Эти признаки представляют категории или классы.\n",
        "    Например:\n",
        "    - Цвет автомобиля (красный, зеленый, синий)\n",
        "    - Тип жилья (квартира, дом, студия)\n",
        "    - Пол (мужской, женский)\n",
        "    \n",
        "Категориальные данные часто делятся на:\n",
        "\n",
        "- Номинальные: Нет естественного порядка между значениями. Например, цвет или пол.\n",
        "- Порядковые: Существует естественный порядок. Например, уровень образования (начальное, среднее, высшее).\n",
        "- Непрерывные признаки: Это количественные данные, которые могут принимать любое значение в определенном диапазоне. Например:\n",
        "    - Возраст\n",
        "    - Вес\n",
        "    - Температура\n",
        "    - Обработка категориальных данных\n",
        "\n",
        "Категориальные данные необходимо преобразовать перед использованием в большинстве алгоритмов машинного обучения. Существуют различные методы:\n",
        "\n",
        "- One-Hot Encoding: Каждая категория преобразуется в новый столбец, где 1 обозначает наличие категории, а 0 — ее отсутствие.\n",
        "- Label Encoding: Каждой категории присваивается уникальный номер. Этот метод хорош для порядковых данных, но может ввести ложное понятие порядка в номинальных данных.\n",
        "- Binary Encoding: Пеобразует категории в двоичный код. Это уменьшает количество новых столбцов по сравнению с One-Hot Encoding и устраняет проблему с ложным порядком, присущим Label Encoding.\n",
        "- Frequency Encoding: Заменяет категории на их частоту встречаемости в данных.\n",
        "- Target Encoding: Заменяет категории на среднее значение целевой переменной для каждой категории. Это особенно полезно, когда категориальные признаки имеют много уникальных значений."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "841f4d6b",
      "metadata": {
        "id": "841f4d6b"
      },
      "source": [
        "## One-hot encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f330227d",
      "metadata": {
        "id": "f330227d"
      },
      "source": [
        "На практике часто используется one-hot encoding. Вместо одного категориального признака $X$ создается набор бинарных категориальных признаков, которые отвечают на вопрос $X == C$, где $C$ перебирает все возможные значения категориального признака.\n",
        "\n",
        "Теперь, чтобы выбрать конкретное значение категориального признака, дереву решений достаточно задать один вопрос."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "746fffd8",
      "metadata": {
        "id": "746fffd8"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L04/out/one_hot_encoding.png\" width=\"450\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "139cc558",
      "metadata": {
        "id": "139cc558"
      },
      "source": [
        "У такой схемы есть ряд недостатков:\n",
        "\n",
        "1. Мы получаем линейно зависимые признаки. Это может плохо влиять на некоторые модели. Например, в линейных моделях линейная зависимость признаков приводит к тому, что решение оптимизационной задачи (результат подбора весов) может быть не уникальным и сколь угодно большим по модулю, что негативно сказывается на работе модели. Подробнее об этом можно почитать по [ссылке](https://inmachineswetrust.com/posts/drop-first-columns/)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa198cb4",
      "metadata": {
        "id": "fa198cb4"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L04/out/problem_of_ohe.png\" width=\"850\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dad9694b",
      "metadata": {
        "id": "dad9694b"
      },
      "source": [
        "Поэтому одну из категорий могут исключить при кодировании. Например, в примере выше можно исключить **Рыбу**, ведь если все три других признака-категории равны 0, то точно верно, что категория — **Рыба**.\n",
        "\n",
        "2. При использовании one-hot encoding один категориальный признак может преобразовываться в десятки бинарных признаков. При использовании случайного леса выбирается случайное подмножество признаков. Преобразованные во множество бинарных, категориальные признаки будут встречаться чаще, чем вещественные, что может привести к тому, что значимость категориальных признаков будет завышена."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af245985",
      "metadata": {
        "id": "af245985"
      },
      "source": [
        "Создание метода вручную:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ff527deb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff527deb",
        "outputId": "f18944c1-8f72-4b71-982d-36207cb7a5e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello world\n",
            "\n",
            "[(0, 'a'), (1, 'b'), (2, 'c'), (3, 'd'), (4, 'e'), (5, 'f'), (6, 'g'), (7, 'h'), (8, 'i'), (9, 'j'), (10, 'k'), (11, 'l'), (12, 'm'), (13, 'n'), (14, 'o'), (15, 'p'), (16, 'q'), (17, 'r'), (18, 's'), (19, 't'), (20, 'u'), (21, 'v'), (22, 'w'), (23, 'x'), (24, 'y'), (25, 'z'), (26, ' ')]\n",
            "\n",
            "[7, 4, 11, 11, 14, 26, 22, 14, 17, 11, 3]\n",
            "\n",
            "[[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "h\n"
          ]
        }
      ],
      "source": [
        "from numpy import argmax\n",
        "import numpy as np\n",
        "\n",
        "# define input string\n",
        "data = 'hello world'\n",
        "print(data)\n",
        "print()\n",
        "\n",
        "# define universe of possible input values\n",
        "alphabet = 'abcdefghijklmnopqrstuvwxyz '\n",
        "\n",
        "# enumerate the alphabet\n",
        "print(list(enumerate(alphabet)))\n",
        "print()\n",
        "\n",
        "# define a mapping of chars to integers by dictionary\n",
        "int_to_char = dict(enumerate(alphabet))\n",
        "char_to_int = dict(zip(int_to_char.values(), int_to_char.keys()))\n",
        "\n",
        "# integer encode input data\n",
        "integer_encoded = [ char_to_int[letter] for letter in data]\n",
        "print(integer_encoded)\n",
        "print()\n",
        "\n",
        "# one hot encode\n",
        "onehot_encoded = list()\n",
        "for value in integer_encoded:\n",
        "    letter = np.zeros(len(alphabet), dtype = int)\n",
        "    letter[value] = 1\n",
        "    onehot_encoded.append(list(letter))\n",
        "print(onehot_encoded)\n",
        "\n",
        "# invert encoding\n",
        "inverted = int_to_char[argmax(onehot_encoded[0])]\n",
        "print(inverted)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25cbd7af",
      "metadata": {
        "id": "25cbd7af"
      },
      "source": [
        "Использование готовых реализаций:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "73550ef3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73550ef3",
        "outputId": "a890c498-cd27-4d50-99b2-4b54b90f6989"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cold' 'cold' 'warm' 'cold' 'hot' 'hot' 'warm' 'cold' 'warm' 'hot']\n",
            "[0 0 2 0 1 1 2 0 2 1]\n",
            "[[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 1. 0.]]\n",
            "['cold']\n"
          ]
        }
      ],
      "source": [
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# define example\n",
        "data = ['cold', 'cold', 'warm', 'cold', 'hot', 'hot', 'warm', 'cold', 'warm', 'hot']\n",
        "values = array(data)\n",
        "print(values)\n",
        "\n",
        "# integer encode\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(data)\n",
        "print(integer_encoded)\n",
        "\n",
        "# binary encode\n",
        "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
        "integer_encoded = integer_encoded.reshape(-1, 1)\n",
        "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "print(onehot_encoded)\n",
        "\n",
        "# invert first example\n",
        "inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
        "print(inverted)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afe4940f",
      "metadata": {
        "id": "afe4940f"
      },
      "source": [
        "# Мешок слов (Bag of Words)\n",
        "\n",
        "Модель текстов на естественном языке, в которой каждый документ или текст выглядит как неупорядоченный набор слов без сведений о связях между ними. Его можно представить в виде матрицы, каждая строка в которой соответствует отдельному документу или тексту, а каждый столбец — определенному слову. Ячейка на пересечении строки и столбца содержит количество вхождений слова в соответствующий документ.\n",
        "\n",
        "Для подготовки Мешка слов можно воспользоваться возможностями пакета tm. Этот пакет в качестве объекта работает с так называемым лингвистическим корпусом первого порядка — коллекцией текстов, объединенных общим признаком. В задаче про классификацию рецензий на фильмы, все тексты - это обзоры фильмов. Для того чтобы составить корпус сначала нужно преобразовать тексты в вектор, каждый элемент которого представляет отдельный документ. А потом построить на базе корпуса матрицу «документ-термин». Она и станет мешком слов.\n",
        "\n",
        "Вот так выглядел фрагмент Мешка с наиболее часто употребляемыми словами:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "20b9ad27",
      "metadata": {
        "scrolled": true,
        "id": "20b9ad27",
        "outputId": "1f205ba4-890d-47dc-845b-cf4fa6247b5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-4b8a71d1a649>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Docs act actor actual also anoth  back bad  best better can\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "Docs act actor actual also anoth  back bad  best better can\n",
        "    1   0     0      1    2     1    0   3    0      0   1\n",
        "    2   0     0      0    0     0    0   0    0      0   1\n",
        "    3   0     1      0    0     0    0   1    0      1   0\n",
        "    4   0     1      0    1     2    0   0    0      0   1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e39b75d",
      "metadata": {
        "id": "1e39b75d"
      },
      "source": [
        "# Bag of Words или Word Embeddings?\n",
        "\n",
        "В некоторых случаях использование BoW может быть предпочтительнее использования Word Embedding. Например:\n",
        "- При построении не очень сложных моделей проще воспользоваться готовой библиотекой scikit-learn, что займёт всего несколько строк кода вместо использования методов Deep Learning для построения Embedding.\n",
        "- Если Вы работаете с небольшим набором данных, в которых специфический контекст, BoW может справиться лучше Word Embedding. Контекст сильно зависит от предметной области, что может привести к тому, что не всегда можно будет найти соответствующий вектор из предварительно обученных моделей (GloVe, fastText etc).\n",
        "\n",
        "Разберём три основных метода по построению BoW с ипользованием готовых библиотек."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6ead3f8c",
      "metadata": {
        "id": "6ead3f8c"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9c93286f",
      "metadata": {
        "id": "9c93286f"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "train_raw_df = fetch_20newsgroups(subset='train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "14302b5e",
      "metadata": {
        "id": "14302b5e"
      },
      "outputs": [],
      "source": [
        "x_train = train_raw_df.data\n",
        "y_train = train_raw_df.target"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ad3140f",
      "metadata": {
        "id": "4ad3140f"
      },
      "source": [
        "## Подсчёт частоты встречаемости слова\n",
        "\n",
        "Основная идея заключается в том, что важные слова (или сигналы) встречаются чаще остальных. То есть высокая частота встречаемости подразумевает большую важность слова.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c03397fa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "c03397fa",
        "outputId": "e2f72ed2-1c51-4845-9ffc-eead9719ac57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Word  Count\n",
              "16   of      3\n",
              "26  the      3\n",
              "3   bow      2\n",
              "0   and      1\n",
              "28  way      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4b293028-2433-4161-b647-7c3cd919de1e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>of</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>the</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bow</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>and</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>way</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b293028-2433-4161-b647-7c3cd919de1e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4b293028-2433-4161-b647-7c3cd919de1e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4b293028-2433-4161-b647-7c3cd919de1e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2022c0c0-750c-468e-bee1-b4295057c71c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2022c0c0-750c-468e-bee1-b4295057c71c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2022c0c0-750c-468e-bee1-b4295057c71c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "doc = \"In the-state-of-art of the NLP field, Embedding is the \\\n",
        "success way to resolve text related problem and outperform \\\n",
        "Bag of Words ( BoW ). Indeed, BoW introduced limitations \\\n",
        "large feature dimension, sparse representation etc.\"\n",
        "\n",
        "count_vec = CountVectorizer()\n",
        "count_occurs = count_vec.fit_transform([doc])\n",
        "count_occur_df = pd.DataFrame((count, word) for word, count in zip(count_occurs.toarray().tolist()[0], count_vec.get_feature_names_out()))\n",
        "count_occur_df.columns = ['Word', 'Count']\n",
        "count_occur_df.sort_values('Count', ascending=False, inplace=True)\n",
        "count_occur_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5da1e20a",
      "metadata": {
        "id": "5da1e20a"
      },
      "source": [
        "### Нормализованная частота встречаемости\n",
        "\n",
        "Чтобы максимальное значение частоты <<не забивало>> остальные значения, применяется нормализация."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c1a3ac19",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "c1a3ac19",
        "outputId": "0e4bea81-1c0d-40c2-ecf9-85d34209a6bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Word     Count\n",
              "16   of  0.428571\n",
              "26  the  0.428571\n",
              "3   bow  0.285714\n",
              "0   and  0.142857\n",
              "28  way  0.142857"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9128951f-da53-4748-a181-1ca5253936a0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>of</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>the</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bow</td>\n",
              "      <td>0.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>and</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>way</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9128951f-da53-4748-a181-1ca5253936a0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9128951f-da53-4748-a181-1ca5253936a0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9128951f-da53-4748-a181-1ca5253936a0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1968429f-7018-4d2d-afa6-58dde05e0ee2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1968429f-7018-4d2d-afa6-58dde05e0ee2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1968429f-7018-4d2d-afa6-58dde05e0ee2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "doc = \"In the-state-of-art of the NLP field, Embedding is the \\\n",
        "success way to resolve text related problem and outperform \\\n",
        "Bag of Words ( BoW ). Indeed, BoW introduced limitations \\\n",
        "large feature dimension, sparse representation etc.\"\n",
        "\n",
        "norm_count_vec = TfidfVectorizer(use_idf=False, norm='l2')\n",
        "norm_count_occurs = norm_count_vec.fit_transform([doc])\n",
        "norm_count_occur_df = pd.DataFrame((count, word) for word, count in zip(\n",
        "    norm_count_occurs.toarray().tolist()[0], norm_count_vec.get_feature_names_out()))\n",
        "norm_count_occur_df.columns = ['Word', 'Count']\n",
        "norm_count_occur_df.sort_values('Count', ascending=False, inplace=True)\n",
        "norm_count_occur_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1112cfc1",
      "metadata": {
        "id": "1112cfc1"
      },
      "source": [
        "### TF-IDF\n",
        "[Статья на Хабр]('https://habr.com/ru/companies/otus/articles/755772/')\n",
        "\n",
        "Term Frequency-Inverse Document Frequency (TF-IDF) — это один из наиболее распространенных и мощных методов для извлечения признаков из текстовых данных. TF-IDF вычисляет важность каждого слова в документе относительно количества его употреблений в данном документе и во всей коллекции текстов. Этот метод позволяет выделить ключевые слова и понять, какие слова имеют больший вес для определенного документа в контексте всей коллекции."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b7c8de94",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "b7c8de94",
        "outputId": "4781fc49-9737-45c9-9c3c-fc21c2c8db82"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Word     Count\n",
              "16   of  0.428571\n",
              "26  the  0.428571\n",
              "3   bow  0.285714\n",
              "0   and  0.142857\n",
              "28  way  0.142857"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c060de1f-715b-4944-a26f-08b1c2263766\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>of</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>the</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bow</td>\n",
              "      <td>0.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>and</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>way</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c060de1f-715b-4944-a26f-08b1c2263766')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c060de1f-715b-4944-a26f-08b1c2263766 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c060de1f-715b-4944-a26f-08b1c2263766');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-35403207-1287-4f2b-a232-f728453f91b0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-35403207-1287-4f2b-a232-f728453f91b0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-35403207-1287-4f2b-a232-f728453f91b0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "doc = \"In the-state-of-art of the NLP field, Embedding is the \\\n",
        "success way to resolve text related problem and outperform \\\n",
        "Bag of Words ( BoW ). Indeed, BoW introduced limitations \\\n",
        "large feature dimension, sparse representation etc.\"\n",
        "\n",
        "tfidf_vec = TfidfVectorizer()\n",
        "tfidf_count_occurs = tfidf_vec.fit_transform([doc])\n",
        "tfidf_count_occur_df = pd.DataFrame((count, word) for word, count in zip(\n",
        "    tfidf_count_occurs.toarray().tolist()[0], tfidf_vec.get_feature_names_out()))\n",
        "tfidf_count_occur_df.columns = ['Word', 'Count']\n",
        "tfidf_count_occur_df.sort_values('Count', ascending=False, inplace=True)\n",
        "tfidf_count_occur_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6d319c6",
      "metadata": {
        "id": "c6d319c6"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "0358c007",
      "metadata": {
        "id": "0358c007"
      },
      "outputs": [],
      "source": [
        "stop_words = ['a', 'an', 'the']\n",
        "\n",
        "# Basic cleansing\n",
        "def cleansing(text):\n",
        "    global stop_words\n",
        "    # Tokenize: splitting by spaces\n",
        "    tokens = text.lower().split()\n",
        "    # Remove stop words\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# All-in-one preproce\n",
        "def preprocess_x(x):\n",
        "    processed_x = [cleansing(text) for text in x]\n",
        "    return processed_x\n",
        "\n",
        "def build_model(mode):\n",
        "    # Intent to use default paramaters for show case\n",
        "    vect = None\n",
        "    if mode == 'count':\n",
        "        vect = CountVectorizer()\n",
        "    elif mode == 'tf':\n",
        "        vect = TfidfVectorizer(use_idf=False, norm='l2')\n",
        "    elif mode == 'tfidf':\n",
        "        vect = TfidfVectorizer()\n",
        "    else:\n",
        "        raise ValueError('Mode should be either count or tfidf')\n",
        "\n",
        "    return Pipeline([\n",
        "        ('vect', vect),\n",
        "        ('clf' , LogisticRegression(solver='newton-cg',n_jobs=-1))\n",
        "    ])\n",
        "\n",
        "def pipeline(x, y, mode):\n",
        "    processed_x = preprocess_x(x)\n",
        "\n",
        "    model_pipeline = build_model(mode)\n",
        "    cv = KFold(n_splits=5, shuffle=True)\n",
        "\n",
        "    scores = cross_val_score(model_pipeline, processed_x, y, cv=cv, scoring='accuracy')\n",
        "    print(\"Accuracy: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))\n",
        "\n",
        "    return model_pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b61fd55",
      "metadata": {
        "id": "9b61fd55"
      },
      "source": [
        "Проверим, какой номер словаря нам необходим:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c6301762",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6301762",
        "outputId": "54f40eb9-28f3-4133-a52c-ea2e28ec0a22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8777 (+/- 0.0169)\n",
            "Number of Vocabulary: 130107\n"
          ]
        }
      ],
      "source": [
        "x = preprocess_x(x_train)\n",
        "y = y_train\n",
        "\n",
        "model_pipeline = pipeline(x, y, mode='count')\n",
        "model_pipeline.fit(x, y)\n",
        "\n",
        "print('Number of Vocabulary: %d'% (len(model_pipeline.named_steps['vect'].get_feature_names_out())))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68520ff8",
      "metadata": {
        "id": "68520ff8"
      },
      "source": [
        "# Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "c5c136fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5c136fc",
        "outputId": "1fb5c3dd-03a5-4ec8-9c58-7e0761d5ec44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Count Vectorizer------\n",
            "Accuracy: 0.8783 (+/- 0.0112)\n",
            "Using TF Vectorizer------\n",
            "Accuracy: 0.8081 (+/- 0.0279)\n",
            "Using TF-IDF Vectorizer------\n",
            "Accuracy: 0.8925 (+/- 0.0124)\n"
          ]
        }
      ],
      "source": [
        "print('Using Count Vectorizer------')\n",
        "model_pipeline = pipeline(x, y, mode='count')\n",
        "\n",
        "print('Using TF Vectorizer------')\n",
        "model_pipeline = pipeline(x, y, mode='tf')\n",
        "\n",
        "print('Using TF-IDF Vectorizer------')\n",
        "model_pipeline = pipeline(x, y, mode='tfidf')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "630e3190",
      "metadata": {
        "id": "630e3190"
      },
      "source": [
        "# Embedding\n",
        "\n",
        "[Хорошая статья на Хабр, полный текст](https://habr.com/ru/companies/ods/articles/329410/)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b6e8775",
      "metadata": {
        "id": "1b6e8775"
      },
      "source": [
        "Визуализация векторов embedding: http://projector.tensorflow.org"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c78cb6e",
      "metadata": {
        "id": "1c78cb6e"
      },
      "source": [
        "Embedding — сопоставление произвольной сущности (например, узла в графе или кусочка картинки) некоторому вектору."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79f63223",
      "metadata": {
        "id": "79f63223"
      },
      "source": [
        "В конце XIX века высказал известный лингвист Фердинанд де Соссюр высказал гипотезу о том, что буквенное написание слова никак не связано с его смыслом.\n",
        "\n",
        "Слова “петух”, “курица” и “цыпленок” имеют очень мало общего между собой и стоят в словаре далеко друг от друга, хотя очевидно обозначают самца, самку и детеныша одного вида птицы. То есть можно выделить два вида близости слов: лексический и семантический. Как мы видим на примере с курицей, эти близости не обязательно совпадают. Можно для наглядности привести обратный пример лексически близких, но семантически далеких слов — \"зола\" и \"золото\".\n",
        "\n",
        "Чтобы получить возможность представить семантическую близость, было предложено использовать embedding, то есть сопоставить слову некий вектор, отображающий его значение в “пространстве смыслов”.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "6b38c262",
      "metadata": {
        "id": "6b38c262"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "aaa55e6f",
      "metadata": {
        "id": "aaa55e6f"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "27b918c5",
      "metadata": {
        "id": "27b918c5"
      },
      "outputs": [],
      "source": [
        "s = ['Mars has an athmosphere', \"Saturn 's moon Titan has its own athmosphere\",\n",
        "     'Mars has two moons', 'Saturn has many moons', 'Io has cryo-vulcanoes']\n",
        "dic = {}\n",
        "for sent in s:\n",
        "    words = sent.split()\n",
        "    for w in words:\n",
        "        if w not in dic:\n",
        "            dic[w] = {}\n",
        "        for w2 in words:\n",
        "            dic[w][w2] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "7f1ef808",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "7f1ef808",
        "outputId": "da9cf20f-3fa3-4bd8-c578-1741eef7c1a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                Mars  has   an  athmosphere  Saturn   's  moon  Titan  its  \\\n",
              "Mars             1.0    1  1.0          1.0     0.0  0.0   0.0    0.0  0.0   \n",
              "has              1.0    1  1.0          1.0     1.0  1.0   1.0    1.0  1.0   \n",
              "an               1.0    1  1.0          1.0     0.0  0.0   0.0    0.0  0.0   \n",
              "athmosphere      1.0    1  1.0          1.0     1.0  1.0   1.0    1.0  1.0   \n",
              "two              1.0    1  0.0          0.0     0.0  0.0   0.0    0.0  0.0   \n",
              "moons            1.0    1  0.0          0.0     1.0  0.0   0.0    0.0  0.0   \n",
              "Saturn           0.0    1  0.0          1.0     1.0  1.0   1.0    1.0  1.0   \n",
              "'s               0.0    1  0.0          1.0     1.0  1.0   1.0    1.0  1.0   \n",
              "moon             0.0    1  0.0          1.0     1.0  1.0   1.0    1.0  1.0   \n",
              "Titan            0.0    1  0.0          1.0     1.0  1.0   1.0    1.0  1.0   \n",
              "its              0.0    1  0.0          1.0     1.0  1.0   1.0    1.0  1.0   \n",
              "own              0.0    1  0.0          1.0     1.0  1.0   1.0    1.0  1.0   \n",
              "many             0.0    1  0.0          0.0     1.0  0.0   0.0    0.0  0.0   \n",
              "Io               0.0    1  0.0          0.0     0.0  0.0   0.0    0.0  0.0   \n",
              "cryo-vulcanoes   0.0    1  0.0          0.0     0.0  0.0   0.0    0.0  0.0   \n",
              "\n",
              "                own  two  moons  many   Io  cryo-vulcanoes  \n",
              "Mars            0.0  1.0    1.0   0.0  0.0             0.0  \n",
              "has             1.0  1.0    1.0   1.0  1.0             1.0  \n",
              "an              0.0  0.0    0.0   0.0  0.0             0.0  \n",
              "athmosphere     1.0  0.0    0.0   0.0  0.0             0.0  \n",
              "two             0.0  1.0    1.0   0.0  0.0             0.0  \n",
              "moons           0.0  1.0    1.0   1.0  0.0             0.0  \n",
              "Saturn          1.0  0.0    1.0   1.0  0.0             0.0  \n",
              "'s              1.0  0.0    0.0   0.0  0.0             0.0  \n",
              "moon            1.0  0.0    0.0   0.0  0.0             0.0  \n",
              "Titan           1.0  0.0    0.0   0.0  0.0             0.0  \n",
              "its             1.0  0.0    0.0   0.0  0.0             0.0  \n",
              "own             1.0  0.0    0.0   0.0  0.0             0.0  \n",
              "many            0.0  0.0    1.0   1.0  0.0             0.0  \n",
              "Io              0.0  0.0    0.0   0.0  1.0             1.0  \n",
              "cryo-vulcanoes  0.0  0.0    0.0   0.0  1.0             1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-56d3d6a9-7eae-4912-a969-83ec3468ff08\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Mars</th>\n",
              "      <th>has</th>\n",
              "      <th>an</th>\n",
              "      <th>athmosphere</th>\n",
              "      <th>Saturn</th>\n",
              "      <th>'s</th>\n",
              "      <th>moon</th>\n",
              "      <th>Titan</th>\n",
              "      <th>its</th>\n",
              "      <th>own</th>\n",
              "      <th>two</th>\n",
              "      <th>moons</th>\n",
              "      <th>many</th>\n",
              "      <th>Io</th>\n",
              "      <th>cryo-vulcanoes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Mars</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>has</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>an</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>athmosphere</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>two</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>moons</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Saturn</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>'s</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>moon</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Titan</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>its</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>own</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>many</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Io</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cryo-vulcanoes</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-56d3d6a9-7eae-4912-a969-83ec3468ff08')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-56d3d6a9-7eae-4912-a969-83ec3468ff08 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-56d3d6a9-7eae-4912-a969-83ec3468ff08');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-200855ee-c66d-4066-a44b-5cda20990d9d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-200855ee-c66d-4066-a44b-5cda20990d9d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-200855ee-c66d-4066-a44b-5cda20990d9d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "df = pd.DataFrame(dic)\n",
        "df.fillna(0, inplace=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "dd07266e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd07266e",
        "outputId": "de1819da-81d2-4098-c900-651fd8dc16c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "1965a3e4",
      "metadata": {
        "id": "1965a3e4"
      },
      "outputs": [],
      "source": [
        "pca = PCA()\n",
        "res = pca.fit_transform(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "06f4388e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "id": "06f4388e",
        "outputId": "643673cc-a391-4a18-cb29-57a8dd5a2d96"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(7,7))\n",
        "plt.scatter(res[:,0], res[:,1])\n",
        "for i, label in enumerate(df):\n",
        "\n",
        "    x, y = res[i,0], res[i,1]\n",
        "    plt.scatter(x, y)\n",
        "    kek = {'has': (1, 50), 'is': (1, 5)}\n",
        "    plt.annotate(label, xy=(x, y), xytext=kek.get(label,(1+i*2, 6*i)), textcoords='offset points',\n",
        "                   ha='right', va='bottom', )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b0f4bcf",
      "metadata": {
        "id": "3b0f4bcf"
      },
      "source": [
        "### Проблемы Embedding\n",
        "Технология эмбединга - одно из самых замечательных изобретений последнего десятилетия. Однако, с ней связан также ряд проблем.\n",
        "\n",
        "* Для получения надёжных контекстных векторов редких слова требуется очень большой корпус текстов. Однако, в большом корпусе может происходить перекос в семантических значениях слов по сравнению с их харатерными обыденными значениями. Например при векторизации GloVe для слова apple получаем следующих ближайших соседей: microsoft(.26), ibm (.32), intel(.32), software(.32), dell (.33). В тоже время существенно меньший корпус ROC Stories выдаёт более \"обыденных соседей\" для apple.\n",
        "\n",
        "* Простой эмбединг не учитывает семантической и синтаксической неоднозначности. Обычно предполагается, что семантическая неоднозначность снимается, после прохождения исходных векторов слов через несколько слоёв нейронной сети, в которых анализируется контекст всего предложения (архитектуры RNN или Attention). Например, общий контекст предложений \"Remove first row of the table.\" и \"Put an apple on the table\" позволяет в каждом случае уточнить семантическое значение слова table.\n",
        "\n",
        "* Так как слова в векторном пространстве являются точками, а не протяжёнными областями, эмбединг не отражает иерархической природы смыслов: предмет - инструмент - молоток."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0d4c53f",
      "metadata": {
        "id": "c0d4c53f"
      },
      "source": [
        "И тогда, как это часто бывает, был предложен выход по принципу “тот, кто нам мешает, тот нам поможет!” А именно, в 2013 году тогда мало кому известный чешский аспирант Томаш Миколов предложил свой подход к word embedding, который он назвал word2vec. Его подход основан на другой важной гипотезе, которую в науке принято называть гипотезой локальности — “слова, которые встречаются в одинаковых окружениях, имеют близкие значения”. Близость в данном случае понимается очень широко, как то, что рядом могут стоять только сочетающиеся слова. Например, для нас привычно словосочетание \"заводной будильник\". А сказать “заводной апельсин” мы не можем* — эти слова не сочетаются."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0722256d",
      "metadata": {
        "id": "0722256d"
      },
      "source": [
        "# word2vec и  skip-gram\n",
        "\n",
        "Оригинальная статья: https://arxiv.org/pdf/1301.3781.pdf\n",
        "\n",
        "Статья на Хабр: https://habr.com/ru/companies/ods/articles/329410/\n",
        "\n",
        "В 2013 году тогда мало кому известный чешский аспирант Томаш Миколов предложил свой подход к word embedding, который он назвал word2vec. Его подход основан на другой важной гипотезе, которую в науке принято называть гипотезой локальности — “слова, которые встречаются в одинаковых окружениях, имеют близкие значения”. Близость в данном случае понимается очень широко, как то, что рядом могут стоять только сочетающиеся слова. Например, для нас привычно словосочетание \"заводной будильник\". А сказать “заводной апельсин” мы не можем — эти слова не сочетаются.\n",
        "\n",
        "Основываясь на этой гипотезе Томаш Миколов предложил новый подход, который не страдал от больших объемов информации, а наоборот выигрывал."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cce63f1e",
      "metadata": {
        "id": "cce63f1e"
      },
      "source": [
        "Модель, предложенная Миколовым очень проста (и потому так хороша) — мы будем предсказывать вероятность слова по его окружению (контексту). То есть мы будем учить такие вектора слов, чтобы вероятность, присваиваемая моделью слову была близка к вероятности встретить это слово в этом окружении в реальном тексте.\n",
        "\n",
        "$$P(w_o| w_c)=\\frac{e^{s(w_o, w_c)}}{\\sum_{w_i \\in V} e^{s(w_i, w_c)}}$$\n",
        "\n",
        "\n",
        "Здесь $w_o$ — вектор целевого слова, $w_c$ — это некоторый вектор контекста, вычисленный (например, путем усреднения) из векторов окружающих нужное слово других слов. А $s(w_1, w_2)$ — это функция, которая двум векторам сопоставляет одно число. Например, это может быть упоминавшееся выше косинусное расстояние.\n",
        "\n",
        "Приведенная формула называется softmax, то есть “мягкий максимум”, мягкий — в смысле дифференцируемый. Это нужно для того, чтобы наша модель могла обучиться с помощью backpropagation, то есть процесса обратного распространения ошибки.\n",
        "\n",
        "Процесс тренировки устроен следующим образом: мы берем последовательно (2k+1) слов, слово в центре является тем словом, которое должно быть предсказано. А окружающие слова являются контекстом длины по k с каждой стороны. Каждому слову в нашей модели сопоставлен уникальный вектор, который мы меняем в процессе обучения нашей модели.\n",
        "\n",
        "В целом, этот подход называется CBOW — continuous bag of words, continuous потому, что мы скармливаем нашей модели последовательно наборы слов из текста, a BoW потому что порядок слов в контексте не важен.\n",
        "\n",
        "Также Миколовым сразу был предложен другой подход — прямо противоположный CBOW, который он назвал skip-gram, то есть “словосочетание с пропуском”. Мы пытаемся из данного нам слова угадать его контекст (точнее вектор контекста). В остальном модель не претерпевает изменений.\n",
        "\n",
        "Что стоит отметить: хотя в модель не заложено явно никакой семантики, а только статистические свойства корпусов текстов, оказывается, что натренированная модель word2vec может улавливать некоторые семантические свойства слов. Классический пример из работы автора:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a190fa6c",
      "metadata": {
        "id": "a190fa6c"
      },
      "source": [
        "<img src = 'https://habrastorage.org/r/w1560/getpro/habr/post_images/9dd/1dc/5ea/9dd1dc5eabaa9a645a12a0a272dd5769.png'>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "025563fa",
      "metadata": {
        "id": "025563fa"
      },
      "source": [
        "Слово \"мужчина\" относится к слову \"женщина\" так же, как слово \"дядя\" к слову \"тётя\", что для нас совершенно естественно и понятно, но в других моделям добиться такого же соотношения векторов можно только с помощью специальных ухищрений. Здесь же — это происходит естественно из самого корпуса текстов. Кстати, помимо семантических связей, улавливаются и синтаксические, справа показано соотношение единственного и множественного числа."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c28b196",
      "metadata": {
        "id": "7c28b196"
      },
      "source": [
        "word2vec — способ построения сжатого пространства векторов слов, использующий нейронные сети. Принимает на вход большой текстовый корпус и сопоставляет каждому слову вектор.\n",
        "\n",
        "Сначала он создает словарь, а затем вычисляет векторное представление слов. Векторное представление основывается на контекстной близости: слова, встречающиеся в тексте рядом с одинаковыми словами (а следовательно, имеющие схожий смысл), в векторном представлении имеют высокое косинусное сходство.\n",
        "\n",
        "<img src = 'https://neerc.ifmo.ru/wiki/images/thumb/e/e1/Words-space.png/1600px-Words-space.png'>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7dd6ce67",
      "metadata": {
        "id": "7dd6ce67"
      },
      "source": [
        "Стоит отметить модель, предложенную лабораторией компьютерной лингвистики Стенфордского университета, под названием [Global Vectors (GloVe)](https://nlp.stanford.edu/projects/glove/), сочетающую в себе черты SVD разложения и word2vec"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fd2dc4c",
      "metadata": {
        "id": "7fd2dc4c"
      },
      "source": [
        "# Использование модели GloVe дл работы с векторами\n",
        "\n",
        "GloVe тесно ассоциируется с Word2Vec: алгоритмы появились примерно в одно и то же время и опираются на интерпретируемость векторов слов. Модель GloVe пытается решить проблему эффективного использования статистики совпадений. GloVe минимизирует разницу между произведением векторов слов и логарифмом вероятности их совместного появления с помощью стохастического градиентного спуска. Полученные представления отражают важные линейные подструктуры векторного пространства слов: получается связать вместе разные спутники одной планеты или почтовый код города с его названием.\n",
        "\n",
        "В Word2Vec частота совместной встречаемости слов не имеет большого значения, она лишь помогает генерировать дополнительные обучающие выборки. GloVe учитывает совместную встречаемость, а не полагается только на контекстную статистику. Векторы слов группируются вместе на основе их глобальной схожести.\n",
        "\n",
        "Преимущества:\n",
        "\n",
        "- Простая архитектура без нейронной сети.\n",
        "- Модель быстрая, и этого может быть достаточно для простых приложений.\n",
        "- GloVe улучшает Word2Vec. Она добавляет частоту встречаемости слов и опережает Word2Vec на большинстве бенчмарков.\n",
        "- Осмысленные эмбеддинги.\n",
        "\n",
        "Недостатки:\n",
        "\n",
        "- Хотя матрица совместной встречаемости предоставляет глобальную информацию, GloVe остаётся обученной на уровне слов и даёт немного данных о предложении и контексте, в котором слово используется.\n",
        "- Плохо обрабатывает неизвестные и редкие слова.\n",
        "\n",
        "Ссылки на дополнительную литературу:\n",
        "\n",
        "* https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/\n",
        "* https://blog.acolyer.org/2016/04/22/glove-global-vectors-for-word-representation/\n",
        "* https://levyomer.wordpress.com/2014/04/25/linguistic-regularities-in-sparse-and-explicit-word-representations/"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9155a7dc",
      "metadata": {
        "id": "9155a7dc"
      },
      "source": [
        "Загрузим необходимые библиотеки и модель GloVe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "ed062215",
      "metadata": {
        "id": "ed062215"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchtext.vocab as vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "34ab0ac8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34ab0ac8",
        "outputId": "24720979-d8cf-4e73-b45b-cece282dc3de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:40, 5.38MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:26<00:00, 15270.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 400000 words\n"
          ]
        }
      ],
      "source": [
        "glove = vocab.GloVe(name='6B', dim=100)\n",
        "\n",
        "print('Loaded {} words'.format(len(glove.itos)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6025231",
      "metadata": {
        "id": "a6025231"
      },
      "source": [
        "Объект класса `GloVe` включает следующие атрибуты:\n",
        "- `stoi` _string-to-index_ возвращает словарь слова-индексы;\n",
        "- `itos` _index-to-string_ возвращает массив слов по индексу;\n",
        "- `vectors` возвращает сформированные на данный момент векторы.\n",
        "\n",
        "Чтобы получить слово по вектору создадим функцию:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "7935edaa",
      "metadata": {
        "scrolled": true,
        "id": "7935edaa"
      },
      "outputs": [],
      "source": [
        "def get_word(word):\n",
        "    return glove.vectors[glove.stoi[word]]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_word('dog')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYSGSvpKEyLq",
        "outputId": "e12dd233-afa1-47d6-f952-48fdfd22d162"
      },
      "id": "CYSGSvpKEyLq",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.3082,  0.3094,  0.5280, -0.9254, -0.7367,  0.6348,  0.4420,  0.1026,\n",
              "        -0.0914, -0.5661, -0.5327,  0.2013,  0.7704, -0.1398,  0.1373,  1.1128,\n",
              "         0.8930, -0.1787, -0.0020,  0.5729,  0.5948,  0.5043, -0.2899, -1.3491,\n",
              "         0.4276,  1.2748, -1.1613, -0.4108,  0.0428,  0.5487,  0.1890,  0.3759,\n",
              "         0.5803,  0.6697,  0.8116,  0.9386, -0.5100, -0.0701,  0.8282, -0.3535,\n",
              "         0.2109, -0.2441, -0.1655, -0.7836, -0.4848,  0.3897, -0.8636, -0.0164,\n",
              "         0.3198, -0.4925, -0.0694,  0.0189, -0.0983,  1.3126, -0.1212, -1.2399,\n",
              "        -0.0914,  0.3529,  0.6464,  0.0896,  0.7029,  1.1244,  0.3864,  0.5208,\n",
              "         0.9879,  0.7995, -0.3462,  0.1409,  0.8017,  0.2099, -0.8601, -0.1531,\n",
              "         0.0745,  0.4082,  0.0192,  0.5159, -0.3443, -0.2453, -0.7798,  0.2743,\n",
              "         0.2242,  0.2016,  0.0174, -0.0147, -1.0235, -0.3970, -0.0056,  0.3057,\n",
              "         0.3175,  0.0214,  0.1184, -0.1132,  0.4246,  0.5340, -0.1672, -0.2718,\n",
              "        -0.6255,  0.1288,  0.6253, -0.5209])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c83b896b",
      "metadata": {
        "id": "c83b896b"
      },
      "source": [
        "Нахождение ближайших векторов.\n",
        "\n",
        "Отображение word &rarr; vector устроено проще, чем отображение vector &rarr; word. Автор предлагает посчитать попарное расстояние между всеми словами в словаре и отсортировать по увеличению полученных значений расстояний."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "a60e3e6e",
      "metadata": {
        "id": "a60e3e6e"
      },
      "outputs": [],
      "source": [
        "def closest(vec, n=10):\n",
        "    \"\"\"\n",
        "    Find the closest words for a given vector\n",
        "    \"\"\"\n",
        "    all_dists = [(w, torch.dist(vec,get_word(w))) for w in glove.itos ]\n",
        "    return sorted(all_dists, key=lambda t: t[1])[:n]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "closest(get_word('funny'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rIBu3tzEt3a",
        "outputId": "c197f73b-fd51-4ed9-f37e-b2e998597be5"
      },
      "id": "_rIBu3tzEt3a",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('funny', tensor(0.)),\n",
              " ('hilarious', tensor(3.5591)),\n",
              " ('amusing', tensor(3.6483)),\n",
              " ('weird', tensor(3.8879)),\n",
              " ('scary', tensor(3.9426)),\n",
              " ('joke', tensor(4.1305)),\n",
              " ('fun', tensor(4.1596)),\n",
              " ('witty', tensor(4.1683)),\n",
              " ('cute', tensor(4.2088)),\n",
              " ('silly', tensor(4.2213))]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "closest(get_word('google'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkr53b8SG6FE",
        "outputId": "ea33704a-3733-4f1f-d0ab-293fe0a60ab2"
      },
      "id": "kkr53b8SG6FE",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('google', tensor(0.)),\n",
              " ('yahoo', tensor(3.0772)),\n",
              " ('microsoft', tensor(3.8836)),\n",
              " ('web', tensor(4.1048)),\n",
              " ('aol', tensor(4.1082)),\n",
              " ('facebook', tensor(4.1165)),\n",
              " ('ebay', tensor(4.3917)),\n",
              " ('msn', tensor(4.4122)),\n",
              " ('internet', tensor(4.4540)),\n",
              " ('netscape', tensor(4.4651))]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "closest(get_word('apple'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7pnHfDdG81Z",
        "outputId": "557db1e7-874e-4a92-8439-54be59af8dd6"
      },
      "id": "C7pnHfDdG81Z",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('apple', tensor(0.)),\n",
              " ('microsoft', tensor(4.5067)),\n",
              " ('dell', tensor(4.7019)),\n",
              " ('ibm', tensor(4.7097)),\n",
              " ('intel', tensor(4.8576)),\n",
              " ('pc', tensor(4.9003)),\n",
              " ('hewlett', tensor(4.9201)),\n",
              " ('compaq', tensor(4.9260)),\n",
              " ('macintosh', tensor(4.9678)),\n",
              " ('packard', tensor(5.0125))]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a7e362f",
      "metadata": {
        "id": "9a7e362f"
      },
      "source": [
        "Функция возвращает пару `(word, distance)`. Для более удобного выводы на экран зададим функцию:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "8e1da5b4",
      "metadata": {
        "id": "8e1da5b4"
      },
      "outputs": [],
      "source": [
        "def print_tuples(tuples):\n",
        "    for tuple in tuples:\n",
        "        print('(%.4f) %s' % (tuple[1], tuple[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0c48b8c",
      "metadata": {
        "id": "d0c48b8c"
      },
      "source": [
        "Найдём ближайшие слова к заданному слову:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "34c6347d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34c6347d",
        "outputId": "8d01fad3-a7ad-439d-ae91-7042026841a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.0000) google\n",
            "(3.0772) yahoo\n",
            "(3.8836) microsoft\n",
            "(4.1048) web\n",
            "(4.1082) aol\n",
            "(4.1165) facebook\n",
            "(4.3917) ebay\n",
            "(4.4122) msn\n",
            "(4.4540) internet\n",
            "(4.4651) netscape\n"
          ]
        }
      ],
      "source": [
        "print_tuples(closest(get_word('google')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "1d3cb4de",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d3cb4de",
        "outputId": "5a3a01b0-ff6f-4416-e964-a746bcd880a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0.0000) apple\n",
            "(4.5067) microsoft\n",
            "(4.7019) dell\n",
            "(4.7097) ibm\n",
            "(4.8576) intel\n",
            "(4.9003) pc\n",
            "(4.9201) hewlett\n",
            "(4.9260) compaq\n",
            "(4.9678) macintosh\n",
            "(5.0125) packard\n"
          ]
        }
      ],
      "source": [
        "print_tuples(closest(get_word('apple')))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9eccbfc9",
      "metadata": {
        "id": "9eccbfc9"
      },
      "source": [
        "## Аналогии из векторной арифметики для работы со словами\n",
        "\n",
        "Самая интересная особенность хорошо обученного векторного пространства слов заключается в том, что определенные семантические отношения (помимо близости слов) можно уловить с помощью обычной векторной арифметики.\n",
        "\n",
        "<img src = 'https://i.imgur.com/d0KuM5x.png'>\n",
        "\n",
        "(изображение взято из презентации [Omer Levy и Yoav Goldberg](https://levyomer.wordpress.com/2014/04/25/linguistic-regularities-in-sparse-and-explicit-word-representations/))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "88ec020d",
      "metadata": {
        "id": "88ec020d"
      },
      "outputs": [],
      "source": [
        "# In the form w1 : w2 :: w3 : ?\n",
        "def analogy(w1, w2, w3, n=5, filter_given=True):\n",
        "    print('\\n[%s : %s :: %s : ?]' % (w1, w2, w3))\n",
        "\n",
        "    # w2 - w1 + w3 = w4\n",
        "    closest_words = closest(get_word(w2) - get_word(w1) + get_word(w3))\n",
        "\n",
        "    # Optionally filter out given words\n",
        "    if filter_given:\n",
        "        closest_words = [t for t in closest_words if t[0] not in [w1, w2, w3]]\n",
        "\n",
        "    print_tuples(closest_words[:n])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e94a73f",
      "metadata": {
        "id": "5e94a73f"
      },
      "source": [
        "Классический пример из статьи Томаша Миколова:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "f00e3705",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f00e3705",
        "outputId": "6b92482d-10e5-40f7-dd1e-bf7102f1286e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[king : man :: queen : ?]\n",
            "(4.0811) woman\n",
            "(4.6916) girl\n",
            "(5.2703) she\n",
            "(5.2788) teenager\n",
            "(5.3084) boy\n"
          ]
        }
      ],
      "source": [
        "analogy('king', 'man', 'queen')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "820fd840",
      "metadata": {
        "id": "820fd840"
      },
      "source": [
        "Посмотрим на другие примеры:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "50ce5b08",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50ce5b08",
        "outputId": "0e748c59-b113-4dbc-ee1f-0a84d8eb9787"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[man : actor :: woman : ?]\n",
            "(2.8133) actress\n",
            "(5.0039) comedian\n",
            "(5.1399) actresses\n",
            "(5.2773) starred\n",
            "(5.3085) screenwriter\n",
            "\n",
            "[cat : kitten :: dog : ?]\n",
            "(3.8146) puppy\n",
            "(4.2944) rottweiler\n",
            "(4.5888) puppies\n",
            "(4.6086) pooch\n",
            "(4.6520) pug\n",
            "\n",
            "[dog : puppy :: cat : ?]\n",
            "(3.8146) kitten\n",
            "(4.0255) puppies\n",
            "(4.1575) kittens\n",
            "(4.1882) pterodactyl\n",
            "(4.1945) scaredy\n",
            "\n",
            "[russia : moscow :: france : ?]\n",
            "(3.2697) paris\n",
            "(4.6857) french\n",
            "(4.7085) lyon\n",
            "(4.9087) strasbourg\n",
            "(5.0362) marseille\n",
            "\n",
            "[obama : president :: trump : ?]\n",
            "(6.4302) executive\n",
            "(6.5149) founder\n",
            "(6.6997) ceo\n",
            "(6.7524) hilton\n",
            "(6.7729) walt\n",
            "\n",
            "[rich : mansion :: poor : ?]\n",
            "(5.8262) residence\n",
            "(5.9444) riverside\n",
            "(6.0283) hillside\n",
            "(6.0328) abandoned\n",
            "(6.0681) bungalow\n",
            "\n",
            "[elvis : rock :: eminem : ?]\n",
            "(5.6597) rap\n",
            "(6.2057) rappers\n",
            "(6.2161) rapper\n",
            "(6.2444) punk\n",
            "(6.2690) hop\n",
            "\n",
            "[paper : newspaper :: screen : ?]\n",
            "(4.7810) tv\n",
            "(5.1049) television\n",
            "(5.3818) cinema\n",
            "(5.5524) feature\n",
            "(5.5646) shows\n",
            "\n",
            "[monet : paint :: michelangelo : ?]\n",
            "(6.0782) plaster\n",
            "(6.3768) mold\n",
            "(6.3922) tile\n",
            "(6.5819) marble\n",
            "(6.6524) image\n",
            "\n",
            "[beer : barley :: wine : ?]\n",
            "(5.6021) grape\n",
            "(5.6760) beans\n",
            "(5.8174) grapes\n",
            "(5.9035) lentils\n",
            "(5.9454) figs\n",
            "\n",
            "[earth : moon :: sun : ?]\n",
            "(6.2294) lee\n",
            "(6.4125) kang\n",
            "(6.4644) tan\n",
            "(6.4757) yang\n",
            "(6.4853) lin\n",
            "\n",
            "[house : roof :: castle : ?]\n",
            "(6.2919) stonework\n",
            "(6.3779) masonry\n",
            "(6.4773) canopy\n",
            "(6.4954) fortress\n",
            "(6.5259) battlements\n",
            "\n",
            "[building : architect :: software : ?]\n",
            "(5.8369) programmer\n",
            "(6.8881) entrepreneur\n",
            "(6.9240) inventor\n",
            "(6.9730) developer\n",
            "(6.9949) innovator\n",
            "\n",
            "[boston : bruins :: phoenix : ?]\n",
            "(3.8546) suns\n",
            "(4.1968) mavericks\n",
            "(4.6126) coyotes\n",
            "(4.6894) mavs\n",
            "(4.6971) knicks\n",
            "\n",
            "[good : heaven :: bad : ?]\n",
            "(4.3959) hell\n",
            "(5.2864) ghosts\n",
            "(5.2898) hades\n",
            "(5.3414) madness\n",
            "(5.3520) purgatory\n",
            "\n",
            "[jordan : basketball :: woods : ?]\n",
            "(5.8607) golf\n",
            "(6.4110) golfers\n",
            "(6.4418) tournament\n",
            "(6.4593) tennis\n",
            "(6.6560) collegiate\n"
          ]
        }
      ],
      "source": [
        "analogy('man', 'actor', 'woman')\n",
        "analogy('cat', 'kitten', 'dog')\n",
        "analogy('dog', 'puppy', 'cat')\n",
        "analogy('russia', 'moscow', 'france')\n",
        "analogy('obama', 'president', 'trump')\n",
        "analogy('rich', 'mansion', 'poor')\n",
        "analogy('elvis', 'rock', 'eminem')\n",
        "analogy('paper', 'newspaper', 'screen')\n",
        "analogy('monet', 'paint', 'michelangelo')\n",
        "analogy('beer', 'barley', 'wine')\n",
        "analogy('earth', 'moon', 'sun') # Interesting failure mode\n",
        "analogy('house', 'roof', 'castle')\n",
        "analogy('building', 'architect', 'software')\n",
        "analogy('boston', 'bruins', 'phoenix')\n",
        "analogy('good', 'heaven', 'bad')\n",
        "analogy('jordan', 'basketball', 'woods')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d765927e",
      "metadata": {
        "id": "d765927e"
      },
      "source": [
        "# Токенизация и токены"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3a073d4",
      "metadata": {
        "id": "a3a073d4"
      },
      "source": [
        "Процесс токенизации - это процесс перевода объектов в цифровой вид. В контексте нейронных сетей процедура токенизации — преобразование текста в последовательность чисел.\n",
        "\n",
        "Под *токеном* в контексте нейронных сетей понимается часть текста (слово или часть слова), которой сопоставляется число.\n",
        "\n",
        "<img src = 'https://www.thoughtvector.io/blog/subword-tokenization/subword-units.svg'>\n",
        "\n",
        "Пример токенизации текста при помощи токенайзера ruGPT-3:\n",
        "```\n",
        "text: Токенизируй меня\n",
        "tokens:  [789, 368, 337, 848, 28306, 703]\n",
        "decoded tokens:  ['Т', 'ок', 'ени', 'зи', 'руй', ' меня']\n",
        "```\n",
        "\n",
        "\n",
        "Если в качестве токенов брать просто слова, то такие словари будут иметь очень большую размерность. А если в качестве токена брать буквы, то словарь будет небольшим, но результатом токенизации будет вектор очень большой размерности."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "005fbcc4",
      "metadata": {
        "id": "005fbcc4"
      },
      "source": [
        "## Токенизация"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e30a2e97",
      "metadata": {
        "id": "e30a2e97"
      },
      "source": [
        "На практике часто встает вопрос о том, как делить текст на естественном языке на токены. Должны ли это быть символы, слова, или части слов? Рассмотрим подходы к тому, как производится токенизация в современных языковых моделях."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00b12104",
      "metadata": {
        "id": "00b12104"
      },
      "source": [
        "### Наивная токенизация"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e101751",
      "metadata": {
        "id": "7e101751"
      },
      "source": [
        "Рассмотрим предложение: `Я люблю Natural Language Processing (NLP). А ты?`\n",
        "\n",
        "Присваивать отдельный индекс каждому предложению, кажется, совсем не оптимально. Что тогда? Мы можем разбить предложение на слова (*токенезировать предложение*) по пробелам."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "aefb2d45",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aefb2d45",
        "outputId": "8aa084f2-7135-4164-a422-28f337aea254"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Я', 'люблю', 'Natural', 'Language', 'Processing', '(NLP).', 'А', 'ты?']\n"
          ]
        }
      ],
      "source": [
        "input = \"Я люблю Natural Language Processing (NLP). А ты?\"\n",
        "tokenized = input.split()\n",
        "print(tokenized)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28885122",
      "metadata": {
        "id": "28885122"
      },
      "source": [
        "Неплохо, но можно обратить внимание, что мы не учли пунктуацию. Кажется неразумным создавать отдельный индекс для каждой комбинации NLP и знаков препинания. Давайте проведём токенизацию с учётом знаков препинания."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "3e9a28f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e9a28f7",
        "outputId": "02f225b1-0701-4f45-f987-621880fd310d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Я', 'люблю', 'Natural', 'Language', 'Processing', '(', 'NLP', ').', 'А', 'ты', '?']\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# initializing string\n",
        "input = \"Я люблю Natural Language Processing (NLP). А ты?\"\n",
        "\n",
        "# using findall() to get all regex matches.\n",
        "res = re.findall(r\"\\w+|[^\\s\\w]+\", input)\n",
        "\n",
        "# printing result\n",
        "print(str(res))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b008e25",
      "metadata": {
        "id": "3b008e25"
      },
      "source": [
        "Лучше, но представьте себе размер словаря, если мы будем токенизировать таким образом все слова в Википедии. Такой большой объём словаря приведёт к тому, что у модели будет огромный размер эмбеддингов в качестве входного и выходного слоя, что приведёт к увеличению необходимой памяти. Обычно размер словаря трансформеров не превышает 50 000 токенов. Почему бы тогда не использовать посимвольную токенезацию, как раньше?\n",
        "\n",
        "Хотя посимвольная токенизация очень проста и значительно снижает требования к памяти, она значительно усложняет обучение модели осмысленным представлениям входных данных. Например, выучить осмысленное контекстно-независимое представление для буквы `\"с\"` гораздо сложнее, чем выучить контекстно-независимое представление для слова `\"сегодня\"`. Поэтому токенизация символов часто сопровождается потерей производительности. Чтобы получить лучшее из двух миров, используют что-то среднее между токенизацией на уровне слов и на уровне символов, называемый токенизацией подслова (*subword tokenization*).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c415da23",
      "metadata": {
        "id": "c415da23"
      },
      "source": [
        "### Subword Tokenization (Токенизация подслова)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15430737",
      "metadata": {
        "id": "15430737"
      },
      "source": [
        "Алгоритмы токенизации подслова основываются на принципе, что часто используемые слова не должны разбиваться на более мелкие подслова, а редкие слова должны быть разложены на значимые подслова. Например, слово \"*annoyingly*\" может считаться редким словом и может быть разложено на \"*annoying*\" и \"*ly*\". И \"*annoying*\", и \"*ly*\" как самостоятельные подслова будут встречаться чаще, и в то же время значение слова \"*annoyingly*\" сохранится за счёт составного значения \"*annoying*\" и \"*ly*\".\n",
        "\n",
        "Токенизация подслова позволяет модели иметь разумный объём словаря и при этом обучаться значимым контекстно-независимым представлениям. Кроме того, токенизация подслова позволяет модели обрабатывать слова, которые она никогда раньше не видела, путём разложения их на известные подслова.\n",
        "\n",
        "Воспользуемся популярной библиотекой для токенизации от команды Hugging Face `transformers`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d78a3bf6",
      "metadata": {
        "id": "d78a3bf6"
      },
      "source": [
        "Предложение сначала было приведено к нижнему регистру. Мы видим, что слова [\"i\", \"have\", \"a\", \"new\"] присутствуют в словаре токенизатора, а слово \"annoyingly\" — нет. Следовательно, токенизатор разбивает \"annoyingly\" на известные подслова: [\"annoying\" и \"##ly\"]. \"##\" означает, что остальная часть лексемы должна быть присоединена к предыдущей без пробела (для декодирования или обратного хода токенизации)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ee88bea",
      "metadata": {
        "id": "0ee88bea"
      },
      "source": [
        "### Byte-Pair Encoding (BPE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f897a93b",
      "metadata": {
        "id": "f897a93b"
      },
      "source": [
        "Кодирование байт-парой (BPE) опирается на претокенизатор, который разбивает обучающие данные на слова. Примером простой претокенизации может быть разбивка по пробелам. Более продвинутая предварительная токенизация включает токенизацию на основе каких-то правил.\n",
        "\n",
        "После предварительной токенизации у нас получится набор уникальных слов и будет определена частота встречаемости каждого слова в обучающих данных. Затем BPE создаёт базовый словарь, состоящий из всех символов, которые встречаются в наборе уникальных слов, и изучает правила слияния для формирования нового символа из двух символов базового словаря. Так происходит до тех пор, пока словарный запас не достигнет желаемого размера. Обратите внимание, что желаемый объём словаря — это гиперпараметр, который необходимо определить перед обучением токенизатора.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eb1cdfbf",
      "metadata": {
        "id": "eb1cdfbf"
      },
      "source": [
        "**Пример**: после предварительной токенизации был определён набор слов, включая их частоту:\n",
        "\n",
        "`(\"hug\", 10), (\"pug\", 5), (\"pun\", 12), (\"bun\", 4), (\"hugs\", 5)`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0bf1eb0",
      "metadata": {
        "id": "c0bf1eb0"
      },
      "source": [
        "Видим, что базовый словарь —  `[\"b\", \"g\", \"h\", \"n\", \"p\", \"s\", \"u\"]`.\n",
        "\n",
        "Разделим все слова на отдельные буквы:\n",
        "\n",
        "`(\"h\" \"u\" \"g\", 10), (\"p\" \"u\" \"g\", 5), (\"p\" \"u\" \"n\", 12), (\"b\" \"u\" \"n\", 4), (\"h\" \"u\" \"g\" \"s\", 5)`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "763979ec",
      "metadata": {
        "id": "763979ec"
      },
      "source": [
        "BPE подсчитывает **частоту** каждой возможной пары символов и **выбирает** ту пару символов, которая встречается наиболее часто. В приведённом выше примере `\"h\"`, за которым следует `\"u\"`, встречается 10 + 5 = 15 раз. Однако наиболее частой парой символов является `\"u\"`, за которой следует `\"g\"`, встречающаяся 10 + 5 + 5 = 20 раз. Таким образом, первое правило слияния, которому обучается токенизатор, — сгруппировать все символы `\"u\"`, за которыми следует символ `\"g\"`, вместе. Затем `\"ug\"` добавляется в словарь. После этого набор слов становится следующим:\n",
        "\n",
        "`(\"h\" \"ug\", 10), (\"p\" \"ug\", 5), (\"p\" \"u\" \"n\", 12), (\"b\" \"u\" \"n\", 4), (\"h\" \"ug\" \"s\", 5)`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e38135e",
      "metadata": {
        "id": "5e38135e"
      },
      "source": [
        "Затем BPE определяет следующую наиболее часто встречающуюся пару символов. Это `\"u\"`, за которым следует `\"n\"`, который встречается 16 раз. `\"u\"`, `\"n\"` объединяются в `\"un\"` и добавляются в словарь. Следующая по частоте пара символов — `\"h\"`, за которой следует `\"ug\"`, 15 раз. Снова пара объединяется, и `\"hug\"` может быть добавлен в словарь.\n",
        "\n",
        "На данном этапе словарь состоит из `[\"b\", \"g\", \"h\", \"n\", \"p\", \"s\", \"u\", \"ug\", \"un\", \"hug\"]`, а наш набор уникальных слов представлен как\n",
        "\n",
        "`(\"hug\", 10), (\"p\" \"ug\", 5), (\"p\" \"un\", 12), (\"b\" \"un\", 4), (\"hug\" \"s\", 5)`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "004561ea",
      "metadata": {
        "id": "004561ea"
      },
      "source": [
        "Если остановить обучение BPE на этом моменте, то выученные правила слияния будут применяться к новым словам (при условии, что эти новые слова не содержат символов, которых не было в базовом словаре).\n",
        "\n",
        "Например, слово `\"bug\"` будет токенизировано как `[\"b\", \"ug\"]`, а `\"mug\"` будет токенизировано как `[\"<unk>\", \"ug\"]`, поскольку символ `\"m\"` отсутствует в базовом словаре. Как правило, отдельные буквы, такие как `\"m\"`, не заменяются символом `\"<unk>\"`, поскольку обучающие данные обычно включают хотя бы одно вхождение каждой буквы, но это может произойти и для специальных символов, таких как эмодзи.\n",
        "\n",
        "Размер словаря, т.е. размер базового словаря + количество слияний, является **гиперпараметром**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "48aac090",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48aac090",
        "outputId": "d9ae5e5c-4e79-48ea-f1c1-b963b25c6f73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Мешок слов предложения 1:\n",
            "{'любит': 2, 'фильмы': 2, 'иван': 1, 'смотреть': 1, 'мария': 1, 'тоже': 1}\n",
            "Нашли 6 уникальных токенов.\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "import ast\n",
        "\n",
        "sentence = [\"Иван любит смотреть фильмы. Мария тоже любит фильмы.\"]\n",
        "\n",
        "def print_bow(sentence: str) -> None:\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(sentence)\n",
        "    sequences = tokenizer.texts_to_sequences(sentence)\n",
        "    word_index = ast.literal_eval(tokenizer.get_config()[\"word_index\"])\n",
        "    bow = {}\n",
        "    for key in word_index.keys():\n",
        "        bow[key] = sequences[0].count(word_index[key])\n",
        "\n",
        "    print(f\"Мешок слов предложения 1:\\n{bow}\")\n",
        "    print(f'Нашли {len(word_index)} уникальных токенов.')\n",
        "\n",
        "print_bow(sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3d8adf2",
      "metadata": {
        "id": "b3d8adf2"
      },
      "source": [
        "Есть и множество других форм токенизации, подробнее о них можно прочитать в [Summary of the tokenizers](https://huggingface.co/docs/transformers/tokenizer_summary)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}